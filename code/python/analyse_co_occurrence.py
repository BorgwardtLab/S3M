#!/usr/bin/env python3

import collections
import csv
import json
import math
import mpmath
import tqdm
import sys

import numpy                  as np
import scipy.spatial.distance as ss

from scipy.stats import chi2

# Decimal digits of precision for the multi-precision mathematics
# library.
#
# FIXME: make this configurable?
mpmath.mp.dps = 200

def pdf(x,k):
    x,k = mpmath.mpf(x), mpmath.mpf(k)
    if x < 0: return 0
    return 1/(2**(k/2) * mpmath.gamma(k/2)) * (x**(k/2-1)) * mpmath.exp(-x/2)

def cdf(x,k): 
    x,k = mpmath.mpf(x), mpmath.mpf(k) 
    return mpmath.gammainc(k/2, 0, x/2, regularized=True)

def cdf_via_quad(s,k):
    return mpmath.quad(lambda x: pdf(x,k), [0, s])

def distance(S,T):
    """
    Calculates the Euclidean distance between two sequences of varying
    lengths, using early abandon if possible. Returns the minimum dist
    value and the index at which it occurred.
    """
    n, m = len(S), len(T)
  
    if n > m:
      n,m = m,n
      S,T = T,S
  
    min_distance = np.inf
    min_index    = -1
  
    for i in range(0, m - n + 1):
      stop         = False
      sum_distance = 0.0
  
      for j,x in enumerate(S):
        y             = T[i+j]
        sum_distance += ss.sqeuclidean(x, y)
  
        # Abandon calculations as soon as the best distance (so far) has
        # been surpassed---adding more values will only increase it.
        if sum_distance >= min_distance:
          stop = True
          break

      if not stop:
        min_distance = sum_distance
        min_index    = i

    return min_distance, min_index

def min_attainable_p_value(n, n_1, r_s):
    """
    Calculates the minimum attainable $p$-value that can be achieved
    given the marginals of a contingency table. This function uses a
    a Chi-squared test.
    """

    n_a = np.min([n_1, n - n_1])
    n_b = np.max([n_1, n - n_1])

    if 0 <= r_s and r_s < n_a:
        return mpmath.mpf(1.0) - cdf((n - 1) * ((n_b / float(n_a)) * (     r_s  / float(n - r_s))), 1)
    elif n_a <= r_s and r_s < n / float(2):
        return mpmath.mpf(1.0) - cdf((n - 1) * ((n_a / float(n_b)) * ((n - r_s) / float(r_s))), 1)
    elif n / float(2) <= r_s and r_s < n_b:
        return mpmath.mpf(1.0) - cdf((n - 1) * ((n_a / float(n_b)) * (     r_s  / float(n - r_s))), 1)
    elif n_b <= r_s and r_s <= n:
        return mpmath.mpf(1.0) - cdf((n - 1) * ((n_b / float(n_a)) * ((n - r_s) / float(r_s))), 1)

def pessimistic_p_value(n, r_s):
    """
    Calculates the most pessimistic attainable $p$-value, i.e. the
    smallest one that could possibly be achieved without knowing a
    true frequency of the positive class.
    """

    p = mpmath.mpf(1.0)
    k = -1

    for n_1 in range(1,n+1):
        p_new = min_attainable_p_value(n, n_1, r_s)
        if p_new < p:
            p = p_new
            k = n_1

    return p, k

if __name__ == '__main__':
    with open(sys.argv[1]) as f:
        data = json.load(f)

    ####################################################################
    # Generate shapelet pairs
    ####################################################################
    #
    # Candidates are generated by ensuring that one shapelet precedes
    # the other _and_ they are coming from the same time series.

    shapelets = data['shapelets']
    pairs     = []

    for s in shapelets:
        i   = s['index']
        p_i = s['start']
        for t in shapelets:
            j   = t['index']
            p_j = t['start']

            if i == j and p_i < p_j:
                pairs.append((s,t))

    print('There are {} shapelet pair candidates'.format(len(pairs)))

    ####################################################################
    # Load time series
    ####################################################################

    time_series = []

    with open(sys.argv[2]) as f:
        reader = csv.reader(f)
        for row in reader:
            if row[0].startswith('#'):
                continue

            time_series.append( row[1:] )

    print('Loaded {} time series'.format(len(time_series)))

    counts                     = collections.Counter()
    tqdm.tqdm.monitor_interval = 0
    writer                     = csv.writer(sys.stdout)
    n                          = len(time_series)

    print('Processing pairs...')

    for index, (s,t) in enumerate(tqdm.tqdm(pairs)):
        for T in time_series:
            d_s, i_s = distance(s['shapelet'], T)
            t_s      = s['threshold']

            # Check the second shapelet only if the first shapelet is
            # already known to occur in the time series.
            if d_s <= t_s:
                d_t, i_t = distance(t['shapelet'], T)
                t_t      = t['threshold']

                if d_t <= t['threshold'] and i_s <= i_t:
                    counts[index] += 1

        # Co-occurrence count of the 'amalgamated' pattern, consisting
        # of the two shapelets defined above.
        r_s  = counts[index]
        p, k = pessimistic_p_value(n, r_s)

        # Counts are now available for the given pair, so we can
        # calculate its minimum (pessimistic!) $p$-value.
        writer.writerow([s['index'], s['start'], t['start'], r_s, k, p])
